---
locale: ja-JP
layout: single
title: AI Powered Voice Chat

AIパワードボイスチャット
toc: true
sidebar:
  nav: "docs-jp"
---
[Eng](/dancexr/ai_chat) | [繁中](/tw/dancexr/ai_chat) | [日本語](/jp/dancexr/ai_chat) | [한국어](/kr/dancexr/ai_chat) | [简中](/zh/dancexr/ai_chat)

## AI Powered Voice Chat

### Key features
* OpenAI、ローカルまたはリモートのテキスト生成WebUIをAIサービスとして使用するオプション
* AIが生成したメッセージを音声に変換するための組み込みTTSエンジン
* トーク中にキャラクターの顔を自動的にアニメーションさせる組み込みリップシンク
* 音声認識を組み込んで、あなたの声をテキストに変換してAIに送信する
* 選択できる英語の声が900以上用意されており、各キャラクターに独自の声を設定できる

### 制限事項
* 音声エンジンはWindowsのみ対応です。他のプラットフォームでは音声認識を使用して話すことはできますが、応答はテキストのみです。


## AIサービス
キャラクターに知能を与えるためのAIサービスとして使用できるさまざまなオプションがあります。以下ではそれぞれのオプションの利点と欠点について説明します。

### OpenAI (ChatGPT)
現時点で最も知能が高いオプションです。

**利点:**
* スマート
* 速い
* 他のリモートオプションと比較してコスト効果が高い

**欠点:**
* 検閲されている

**セットアップ:**
DanceXRでOpenAIサービスを使用するには、OpenAI APIキーが必要です。
* OpenAIアカウントに登録してログインします。
* ページの右上隅にあるプロフィールアイコンをクリックします。
* APIページを開くために「View API Keys」を選択します。
* 「Create New Secret Key」をクリックして、キーが表示されたらコピーします。キーはここで**1度だけ**表示されるので、後でフルキーを取得することはできませんので、紛失しないようにしてください。
* DanceXRを開いて、チャットメニューからConfigアイコンをクリックします。
* AIサービスに移動し、OpenAI APIキーを「OpenAI API Key」ボックスに貼り付けます。
* 次に、「AI Service」ドロップダウンで「OpenAI (ChatGPT)」を選択して、設定が完了します。
* チャット設定で使用するモデルを選択できます。


### ローカルでLLMを実行（LM Studio、OobaBoogaなど）
コンピューターが十分に強力な場合、LLMをローカルで実行することもできます。たとえば、最新のLlama3 8bはロールプレイには十分です。OobaBoogaとLM Studioをテストし、DanceXRとの互換性があることを確認しました。

AIの領域は非常に速く発展しており、新しいツールやモデルが常に登場しています。ここでの推奨事項は執筆時点での情報に基づいており、読んでいる時点で時代遅れになっている可能性があります。独自のオプションを探索しても構いません。DanceXRは、OpenAI API仕様をサポートするLLMツールであればどれでも動作するはずです。

**利点:**
* プライバシーが守られ、何も送信されず、すべてがローカルで処理されます。
* 検閲されていないモデルを含む、任意のモデルを選択できます。
* 無料

**欠点:**
* オンラインモデルほどスマートではありません
* 少しのセットアップが必要です
* LLMをローカルで実行すると、非常にリソースを消費する場合があります。特にDanceXRとLLMを同じマシンで実行する場合は。

**セットアップ:**
現時点では、コマンドラインツールをいじることなく使用する場合は、LM Studioがより良い選択肢です。
LM Studioの場合、こちらの手順に従ってください：
* ウェブサイトhttps://lmstudio.ai/からLM Studioをダウンロードしてインストールします。
* LM Studio内からLLMモデルを選択してダウンロードします。現時点では、Llama3 8bの使用をお勧めします。
* チャットタブに切り替えて、ダウンロードしたモデルを読み込みます。
* 「Local Server」タブに移動し、「Start Server」をクリックします。ポート番号をメモしておいてください（デフォルトは1234）。

OobaBoogaの場合、こちらの手順に従ってください：
* ダウンロードしてインストールするための手順はこちらhttps://github.com/oobabooga/text-generation-webuiに従ってください。
* DanceXRでWebUIを使用するためには、APIを有効にする必要があります。これを行うには、CMD_FLAGS.txtファイルを開いて、そこに「--listen --api」と追加し、再起動します。
* 実行中に、モデルタブに移動して、モデルをダウンロードします（すでに持っていない場合）。
* 以下の2つのモデルのいずれかを使用することをお勧めします：https://huggingface.co/TheBloke/Luna-AI-Llama2-Uncensored-GPTQ（7b、実行が容易）https://huggingface.co/TheBloke/Nous-Hermes-Llama2-GPTQ（13b、スマート）
* モデルリストを更新して読み込みます。デフォルトのポート番号は5000です。

DanceXRの設定：
* DanceXRで、AI Service -> Select Serviceから「Local WebUI」を選択します。
* サーバーのURLとポート番号を入力します。たとえば、「http://127.0.0.1:1234」（LM Studio）または「http://127.0.0.1:5000」（OobaBooga）。

### Runpodなどのリモートサービスを使用してWebUIを実行
GPUをレンタルしてAIモデルを実行できるサービスがあります。Runpodがその1つです。彼らはWebUI用のテンプレートを持っており、ローカルで実行するよりも簡単にセットアップできます。

**利点:**
* 速くて簡単
* 実行できないローカルGPU上で実行するモデルを選択できます。

**欠点:**
* OpenAIよりもやや高価
* モデルを実行するたびにダウンロードする必要がありますが、数分で完了します。

**セットアップ:**
* 「Community Cloud」からGPUを選択し、「Deploy」をクリックします。3080tiは13bモデルを実行するのに十分です。1時間あたり26セントかかります。
* テンプレートドロップダウンから「RunPod TheBloke LLMs」を選択します。
* 実行中に、接続をクリックすると、WebUIとAPIのリンクが表示されます。APIのURLをコピーして、DanceXRの「Remote WebUI URL」ボックスに貼り付けます。
* WebUIリンクをクリックして、モデルタブに移動して、モデルをダウンロードします。
* 以下の2つのモデルのいずれかを使用することをお勧めします：https://huggingface.co/TheBloke/Luna-AI-Llama2-Uncensored-GPTQ（7b、実行が容易）https://huggingface.co/TheBloke/Nous-Hermes-Llama2-GPTQ（13b、スマート）
* モデルリストを更新して読み込みます。

## チャットコントロール

### テンプレート
テンプレートは、AIモデルにチャットメッセージを生成させるためのものです。複雑なように思えるかもしれませんが、実際には非常にシンプルです。chat/templatesフォルダを開いて、デフォルトのテンプレートを見ることで、その動作を確認できます。

基本的には、平文で特定のことを誰かに指示するようなものです。デフォルトのテンプレートを変更して、異なる名前で保存して、チャットコンテンツにどのように影響するかを確認できます。たとえば、環境の説明を追加して、チャットのシナリオを設定することができます。

DanceXRでは、Chat Settings -> Templatesに移動して、作成したテンプレートを選択します。

### キャラクター
キャラクターは、俳優モデルの名前から派生しています。たとえば、「Koharu Bouquet Cattleya Hair B Side Ponytail」という名前の場合、「Koharu」がキャラクター名として解釈され、残りの「Bouquet Cattleya Hair B Side Ponytail」が彼女の衣装の説明として使用されます。

キャラクター設定では、キャラクターの説明や性格を入力でき、それがチャットでの振る舞いに大きな影響を与えます。たとえば、誇り高く傲慢なキャラクターを「従順で喜んで従う」と表現するだけで、そのキャラクターの振る舞いが大きく変わります。

「Player」も技術的にはキャラクターです。自分自身の名前、説明、性格を変更して、自分が望むようなキャラクターになることができます。

### ペルソナ
キャラクター設定には、ペルソナドロップダウンもあります。これにより、TavernAIなどのAIロールプレイプログラムからダウンロードしたキャラクターを使用できます。これらは通常、PNG形式で提供されます。PNG画像のメタデータにはキャラクターの説明が含まれています。

このオンラインキャラクターエディタを使用して、PNGキャラクターをjson形式に変換しますhttps://zoltanai.github.io/character-editor/

次に、jsonを「chat/personas」フォルダに配置すると、キャラクター設定のペルソナドロップダウンに表示されます。これを行うと、ペルソナの説明がキャラクターの説明を上書きします。

### チャット履歴
新しいコンテンツを生成するたびに、チャット履歴がAIに送信され、コンテキストを維持するために使用されます。異なるシナリオやトピックに切り替えたい場合は、最初に履歴をクリアして、AIが以前のチャットコンテキストに影響を受けないようにします。これを使用して環境を操作し、チャットを進めることもできます。たとえば、メッセージで何かが起こったことを説明すると、AIはそのコンテキストを継続します。

プロンプト制限に達すると、最も古いメッセージは無視され、コンテキストに含まれません。つまり、AIは過去に遡ることができない可能性があります。

チャットインターフェースでは、チャットメッセージの横にあるアイコンをクリックして、チャット履歴を操作できます。オプションには次のものがあります：

* Regenerate: 以下のすべてのメッセージを削除し、AIにこのメッセージを再生成させる
* Rewrite: メッセージを引き継いで自分で書き直す。これを行う場合は、メッセージの前に名前とコロンを保持する必要があります。そうしないと、システムはこのメッセージの送信元を認識できません。
* Replay: このメッセージからチャット履歴を再生する
* Delete Entry: このメッセージを削除する
* Remove above: これより上のすべてのメッセージを削除する
* Remove below: これより下のすべてのメッセージを削除する

### Temperature
この値は、AIモデルがチャットメッセージを生成する際の自由度を制御します。画像生成と同様に、同じ入力でも、生成は毎回わずかに異なり、Temperatureはその変動範囲を制御します。

### Presense PenaltyとFrequency Penalty
これらの値を増やすと、AIが繰り返しコンテンツを生成する可能性が低くなります。

### Max Generate TokensとMax Prompt Length
LLMにはトークン制限があり、この制限を超えるコンテンツは正しく生成されません。

### Auto GenerateとGenerate For Player
「Auto Generate Next」をオンにして、タイマーが終了するとAIが自動的に次のメッセージを生成できるようにします。

「Generate For Player」をオンにして、AIがプレイヤーのためにメッセージを生成できるようにします。