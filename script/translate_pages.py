import os
import requests
import json
import subprocess
import os
import re

def get_latest_commit_info(file_path):
    """Get the latest commit date for a given file."""
    cmd = f"git log -1 --pretty=format:%ci -- {file_path}"
    result = subprocess.run(cmd.split(), capture_output=True, text=True, check=True)
    return result.stdout.strip()

def is_file_newer_than_translation(file_path, prefix):
    """Check if the given file is newer than its Japanese counterpart."""
    jp_file_path = os.path.join(prefix, file_path)

    if not os.path.exists(jp_file_path):
        # If the Japanese version doesn't exist, the original is "newer".
        return True
    
    commit_date_original = get_latest_commit_info(file_path)
    commit_date_jp = get_latest_commit_info(jp_file_path)

    # If the original file has no commit history, it's not "newer".
    if not commit_date_original:
        return False

    # If the Japanese version has no commit history, the original is "newer".
    if not commit_date_jp:
        return True

    # Return True if the original file's latest commit is more recent than the Japanese version.
    return commit_date_original > commit_date_jp

# Function to read API key from a JSON file
def get_api_key_from_file(file_path):
    with open(file_path, 'r') as file:
        credentials = json.load(file)
        return credentials.get("api_key")

# Get the API key
api_key_path = os.path.expanduser("~/.openai/auth.json")
api_key = get_api_key_from_file(api_key_path)
# print(api_key)

# Define the path to the English content
src_path = 'dancexr'

# Define the paths for the translated content
dst_paths = {
    'jp': 'jp/dancexr',
    'zh': 'zh/dancexr',
    'kr': 'kr/dancexr',
    'tw': 'tw/dancexr'
}

translation = {
    'scene bundle': {
        'zh': '场景包',
        'tw': '場景包',
        'jp': 'シーンバンドル',
        'kr': '씬 번들'
    },
    'asset': {
        'zh': '资源',
        'tw': '資源',
        'jp': 'アセット',
        'kr': '에셋'
    },
    'bone': {
        'zh': '骨骼',
        'tw': '骨骼',
        'jp': 'ボーン',
        'kr': '본'
    },
    'procedural': {
        'zh': '程序化',
        'tw': '程序化',
        'jp': 'プロシージャル',
        'kr': '프로시저'
    },
    'release': {
        'zh': '发布',
        'tw': '發布',
        'jp': 'リリース',
        'kr': '출시'
    },
    'version': {
        'zh': '版本',
        'tw': '版本',
        'jp': 'バージョン',
        'kr': '버전'
    },
    'pro': {
        'zh': '专业版',
        'tw': '專業版',
        'jp': 'プロ版',
        'kr': '프로버전'
    },
    'camera': {
        'zh': '摄影机',
        'tw': '攝影機',
        'jp': 'カメラ',
        'kr': '카메라'
    },
    'creator': {
        'zh': '创作版',
        'tw': '創作版',
        'jp': 'クリエイター版',
        'kr': '크리에이터버전'
    },
    'DanceXR Immersion': {
        'zh': 'DanceXR舞动幻境',
        'tw': 'DanceXR舞動幻境',
        'jp': 'ダンスXR幻境',
        'kr': '댄스XR환경'
    },
    'DanceXR Mix': {
        'zh': 'DanceXR舞动幻影',
        'tw': 'DanceXR舞動幻影',
        'jp': 'ダンスXR幻影',
        'kr': '댄스XR환영'
    },
    'Animate any model, anywhere': {
        'zh': '遍地皆是舞台，模型随意动画',
        'tw': '遍地皆是舞台，模型隨意動畫', 
        'jp': 'どこでも舞台、モデルは自由にアニメーション',
        'kr': '어디든 무대가 되고, 모델은 자유롭게 애니메이션',
    }
}

# Function to call OpenAI API for translation
def translate(text, target_language):
    text = text.replace("permalink: /dancexr/", f"permalink: /{target_language}/dancexr/")
    text = text.replace("nav: \"docs\"", f"nav: \"docs-{target_language}\"")
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    with open("script/translate_page_prompt.txt", 'r', encoding='utf-8') as f:
            template = f.read()

    terms = '\n'.join([f"{i+1}. {key}: {value[target_language]}" for i, (key, value) in enumerate(translation.items()) if target_language in value])
    prompt = template.format(
        target_language=target_language, 
        terms=terms,
        text=text)
    
    print(prompt)

    data = {
        "model": "gpt-3.5-turbo-1106",
        "messages": [{"role": "user", "content": prompt}],
        # "messages": [{"role": "user", "content": f"Please translate the following English text to {target_language}. \nA few keywords and their meaning in this context: \n\"Procedural\": Motion or texture that are generated by program at runtime. \n\"Bone\": Transform that is used in 3D animation to deform a skinned mesh. \n\"Actor\": A 3D character model that can play certain motion. \nThe text to be translated:\n{text}"}],
        # "max_tokens": len(text) * 2,  # Adjust as needed
        "temperature": 0
    }
    response = requests.post(url, json=data, headers=headers)
    print(response.json())
    print("Received translation...")
    translated_text = response.json()['choices'][0]['message']['content'].strip()
    return translated_text

# Function to create directories if they don't exist
def ensure_dir(file_path):
    directory = os.path.dirname(file_path)
    if not os.path.exists(directory):
        os.makedirs(directory)

# Maximum tokens for GPT-3.5-turbo
MAX_TOKENS = 1024
# Roughly estimating 4 characters per token as a heuristic
CHARS_PER_TOKEN = 4
MAX_CHARS = MAX_TOKENS * CHARS_PER_TOKEN

def extract_section(content):
    front_matter_pattern = re.compile(r'---.*?---', re.DOTALL)
    front_matter_match = re.search(front_matter_pattern, content)
    if front_matter_match:
        front_matter = front_matter_match.group()
        content = content.replace(front_matter, "")
    else:
        front_matter = ""
    language_links_pattern = re.compile(r'\[.+\]\(.*\) \| \[.+\]\(.*\) \| \[.+\]\(.*\) \| \[.+\]\(.*\) \| \[.+\]\(.*\)\n')
    links_match = re.search(language_links_pattern, content)
    if links_match:
        links = links_match.group()
        content = content.replace(links_match.group(), "")
    else:
        links = ""
    chunks = split_text(content, MAX_CHARS)
    return front_matter, links, chunks

def split_text(text, max_chars, separator="\n## ", prefix = "## "):
    # Split by section headers and ensure each chunk is under the maximum character limit
    paragraphs = text.split(separator)
    print(f"{len(paragraphs)} paragraphs.")
    chunks = []
    
    # Handle the first paragraph separately to avoid undesired prefixing
    first_paragraph = paragraphs[0] if paragraphs else ""
    remaining_paragraphs = paragraphs[1:] if len(paragraphs) > 1 else []
    current_chunk = first_paragraph
    
    # If the first paragraph is too long, make it a separate chunk
    if len(first_paragraph) > max_chars or len(remaining_paragraphs) == 0:
        chunks.append(first_paragraph)
        first_paragraph = ""
        current_chunk = ""
    
    for paragraph in remaining_paragraphs:
        # If adding the next paragraph exceeds the max length, start a new chunk
        if len(current_chunk) + len(paragraph) > max_chars:
            if current_chunk:  # Avoid appending empty chunks
                chunks.append(current_chunk)
            current_chunk = prefix + paragraph
        else:
            # Prefix with "## " unless it's the very first paragraph
            divider = "" if not current_chunk and not first_paragraph else separator
            current_chunk = current_chunk + divider + paragraph
    
    # Don't forget to append the last chunk
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks

def translate_file(subdir, file):
    print(subdir + " " + file)
    _, file_extension = os.path.splitext(file)
    
    # Check if the file is a .md file
    if file_extension.lower() != '.md':
        return
    
    # Construct the file path
    file_path = os.path.join(subdir, file)
    
    # Translate and save in corresponding directories for each language
    for lang, dst_path in dst_paths.items():
        # Construct the destination file path
        dst_file_path = os.path.join(dst_path, os.path.relpath(file_path, src_path))

        # Check if destination file exists and is newer than source file
        # if os.path.exists(dst_file_path) and os.path.getmtime(dst_file_path) >= os.path.getmtime(file_path):
        #     print(f"Skipping {dst_file_path} because it is newer than source.")
        #     continue
        if not is_file_newer_than_translation(file_path, lang):
            # print(f"Skipping {dst_file_path} because it is newer than source.")
            continue
        
        print(dst_file_path)

        # Read the English content
        with open(file_path, 'r', encoding='utf-8') as f:
            english_content = f.read()
        
        # Split the content into chunks and translate each chunk
        front_matter, links, chunks = extract_section(english_content)
        translated_chunks = []
        print(f"{len(chunks)} chunks to translate.")

        try:
            index = 0
            for chunk in chunks:
                index += 1
                print(f"Translating chunk {index}/{len(chunks)} size: {len(chunk)}...")
                translated_chunks.append(translate(chunk, lang))
                print("Done.")
            
            # Combine the translated chunks and save the result
            translated_content = "\n## ".join(translated_chunks)
            if (links):
                translated_content = links + "\n" + translated_content
            if (front_matter):
                translated_content = front_matter + "\n" + translated_content
            print(f"Saving translated content to {dst_file_path}...")
            
            # Ensure the directory exists
            ensure_dir(dst_file_path)
            
            # Save the translated content
            with open(dst_file_path, 'w', encoding='utf-8') as f:
                f.write(translated_content)
        except Exception as e:
            print(e)
            print(f"Skipping {dst_file_path} due to error...")

translate_file("", "index.md")
# translate_file("", "README.md")
# Iterate through all files in the source path
for subdir, _, files in os.walk(src_path):
    for file in files:
        translate_file(subdir, file)

# print(translate("---\ntitle:test page\nnavigation:docs\n---\n\nThis is a test. \nDanceXR Immersion: Animate any model, anywhere! ", "zh"))