---
locale: ko-KR
layout: single
title: AI 기반 음성 채팅
toc: true
sidebar:
  nav: "docs-kr"
---
[Eng](/dancexr/ai_chat) | [繁中](/tw/dancexr/ai_chat) | [日本語](/jp/dancexr/ai_chat) | [한국어](/kr/dancexr/ai_chat) | [简中](/zh/dancexr/ai_chat)

## AI 기반 음성 채팅

### 주요 기능
* OpenAI, 로컬 또는 원격 텍스트 생성 웹UI를 AI 서비스로 사용할 수 있는 옵션
* AI가 생성한 메시지를 음성으로 변환하는 내장 TTS 엔진
* 대화하는 동안 캐릭터의 얼굴을 자동으로 애니메이션하는 내장 리ップ싱크
* 목소리를 텍스트로 변환하여 AI에 전송하는 내장 음성 인식
* 선택할 수 있는 900개 이상의 영어 음성 포함, 각 캐릭터는 고유한 음성을 가질 수 있음

### 제한 사항
* 음성 엔진은 Windows 전용입니다. 다른 플랫폼에서는 음성 인식을 통해 대화할 수 있지만 응답은 텍스트로만 제공됩니다.


## AI 서비스
캐릭터에 지능을 부여하기 위해 사용할 수 있는 다양한 AI 서비스 옵션이 있습니다. 각 옵션의 장단점을 아래에서 논의하겠습니다.

### OpenAI (ChatGPT)
현재 가장 지능적인 옵션입니다.

**장점:**
* 스마트함
* 빠름
* 비용 효율적 (다른 원격 옵션과 비교)

**단점:**
* 검열됨

**설정:**
DanceXR에서 OpenAI 서비스를 사용하려면 OpenAI API 키가 필요합니다.
* OpenAI 계정을 등록하고 로그인합니다.
* 페이지 오른쪽 상단 모서리에 있는 프로필 아이콘을 클릭합니다.
* "API 키 보기"를 선택하여 API 페이지를 엽니다.
* "새 비밀 키 만들기"를 클릭하고 표시되면 키를 복사합니다. 이 키는 **여기서 한 번만 표시**되므로 나중에 전체 키를 검색할 수 없으니 잃어버리지 마십시오.
* DanceXR을 열고 채팅 메뉴에서 구성 아이콘을 클릭합니다.
* AI 서비스로 가서 "OpenAI API 키" 상자에 키를 붙여넣습니다.
* 그런 다음 "AI 서비스" 드롭다운에서 "OpenAI (ChatGPT)"를 선택하면 됩니다.
* 채팅 설정에서 사용하려는 모델을 선택할 수 있습니다.


### 로컬에서 LLM 실행 (LM Studio, OobaBooga, Ollama)
컴퓨터가 충분히 강력하다면 LLM을 로컬에서 실행할 수도 있습니다. 예를 들어 최신 Llama3 8b는 롤플레이에 충분할 것입니다. OobaBooga, LM Studio 및 Ollama를 테스트했으며 DanceXR과 잘 작동합니다.

AI 영역은 매우 빠르게 발전하고 있으며 항상 새로운 도구와 모델이 출시되고 있습니다. 여기의 추천은 작성 당시 우리가 알고 있는 것에 기반하며, 읽고 있는 시점에서는 최신 정보가 아닐 수 있습니다. 당신만의 옵션을 탐색하실 수 있습니다. DanceXR은 OpenAI API 사양을 지원하는 모든 LLM 도구와 호환되어야 합니다.

**장점:**
* 프라이버시, 아무것도 외부로 전송되지 않음, 모든 것이 로컬에서 발생합니다.
* 실행할 모델을 자유롭게 선택할 수 있으며, 검열되지 않은 모델도 포함됩니다.
* 무료

**단점:**
* 온라인 모델만큼 스마트하지 않음
* 설정이 약간 필요함
* LLM을 로컬에서 실행하는 것은 매우 많은 자원이 필요할 수 있으며, 특히 DanceXR과 LLM을 같은 기계에서 실행할 계획이라면 더욱 그렇습니다.

**설정:**
현재 LM Studio는 명령줄 도구를 다루고 싶지 않다면 더 나은 선택입니다. 
LM Studio의 경우 다음 지침을 따르십시오:
* LM Studio를 [웹사이트](https://lmstudio.ai/)에서 다운로드하고 설치합니다.
* LM Studio 내에서 LLM 모델을 선택하고 다운로드합니다. 현재 Llama3 8b 사용을 추천합니다.
* 채팅 탭으로 전환하고 다운로드한 모델을 로드합니다.
* "로컬 서버" 탭으로 가서 "서버 시작"을 클릭합니다. 포트 번호를 메모하십시오 (기본값은 1234입니다).

OobaBooga의 경우 다음 지침을 따르십시오:
* [여기](https://github.com/oobabooga/text-generation-webui)에서 다운로드 및 설치 지침을 따릅니다.
* DanceXR에서 WebUI가 작동하도록 하려면 API를 활성화해야 합니다. 이를 위해 CMD_FLAGS.txt 파일을 열고 그 안에 "--listen --api"를 추가한 후 재시작합니다.
* 실행 중이면 모델 탭으로 이동하여 모델을 다운로드합니다. 
* 우리는 다음 2개의 모델 중 하나를 사용하는 것을 추천합니다: [Luna-AI-Llama2-Uncensored-GPTQ (7b, 더 쉽게 실행)](https://huggingface.co/TheBloke/Luna-AI-Llama2-Uncensored-GPTQ) 또는 [Nous-Hermes-Llama2-GPTQ (13b, 더 똑똑함)](https://huggingface.co/TheBloke/Nous-Hermes-Llama2-GPTQ)
* 모델 목록을 새로 고침하고 모델을 로드합니다. 기본 포트 번호는 5000입니다.

**Ollama 설정:**
Ollama는 최소한의 설정으로 로컬 AI 모델을 실행하는 쉬운 방법을 제공합니다.
* [Ollama 웹사이트](https://ollama.ai/)에서 Ollama를 다운로드하고 설치합니다.
* Ollama 앱을 열고 원하는 모델을 다운로드합니다.
* DanceXR에서 AI 서비스 -> 서비스 선택에서 "Ollama"를 선택합니다.
* "모델 이름" 상자에 모델 이름을 입력합니다. 예: "llama2-7b-chat".
* 이제 Ollama를 AI 백엔드로 사용할 수 있어야 합니다.

DanceXR의 설정:
* DanceXR에서 AI 서비스 -> 서비스 선택에서 "로컬 WebUI"를 선택합니다.
* 서버 URL과 포트 번호를 입력합니다. 예: "http://127.0.0.1:1234"(LM Studio) 또는 "http://127.0.0.1:5000"(OobaBooga).


### Runpod와 같은 원격 서비스 사용하여 WebUI 실행
AI 모델을 실행하기 위해 GPU를 임대할 수 있는 서비스가 있습니다. Runpod가 그 중 하나입니다. 그들은 WebUI의 템플릿을 가지고 있으며 로컬에서 실행하는 것보다 설정이 더 쉽습니다.

**장점:**
* 빠르고 간편함
* 실행하고자 하는 모델을 자유롭게 선택할 수 있음. 로컬 GPU에서 실행할 수 없는 모델도 포함.

**단점:**
* OpenAI보다 다소 비쌈
* 실행할 때마다 모델을 다운로드해야 함. 그러나 몇 분 밖에 걸리지 않을 것입니다.

**설정:**
* "커뮤니티 클라우드"에서 GPU를 선택하고 "배포"를 클릭합니다. 3080ti는 13b 모델을 실행하기에 충분합니다. 이는 시간당 26센트입니다.
* 템플릿 드롭다운에서 "RunPod TheBloke LLMs"를 선택합니다.
* 실행 중이라면 연결을 클릭하면 WebUI 및 API의 링크가 제공되며, API용 URL을 복사하여 DanceXR의 "원격 WebUI URL" 상자에 붙여넣습니다.
* WebUI 링크를 클릭한 후 모델 탭으로 이동하여 모델을 다운로드합니다.
* 우리는 다음 2개의 모델 중 하나를 사용하는 것을 추천합니다: [Luna-AI-Llama2-Uncensored-GPTQ (7b, 더 쉽게 실행)](https://huggingface.co/TheBloke/Luna-AI-Llama2-Uncensored-GPTQ) 또는 [Nous-Hermes-Llama2-GPTQ (13b, 더 똑똑함)](https://huggingface.co/TheBloke/Nous-Hermes-Llama2-GPTQ).
* 모델 목록을 새로 고침하고 로드합니다.


### 로컬 모델을 위한 개선된 프롬프트
DanceXR은 이제 작은 로컬 모델을 사용할 때 대화 품질을 향상시키기 위한 개선된 프롬프트 기법을 포함합니다. 이를 통해 더 나은 응답과 더 매력적인 상호작용을 보장합니다.


## 채팅 제어

### 템플릿
템플릿은 AI 모델이 각 캐릭터의 채팅 메시지를 생성하도록 유도하는 것입니다. 복잡하다고 생각할 수 있지만 사실은 매우 간단합니다. chat/templates 폴더를 열어 기본 템플릿을 열고 작동 방식을 확인할 수 있습니다.

기본적으로 누군가에게 특정 작업을 텍스트로 지시하는 것과 유사합니다. 기본 템플릿을 수정하고 다른 이름으로 저장하여 그것이 채팅 내용에 어떤 영향을 미치는지 확인할 수 있습니다. 예를 들어, 거기에 환경 설명을 추가하여 채팅의 시나리오를 설정할 수 있습니다.

DanceXR에서는 채팅 설정 -> 템플릿으로 가서 생성한 템플릿을 선택할 수 있습니다.


### 캐릭터
캐릭터는 배우 모델의 이름에서 파생됩니다. 예를 들어 "Koharu Bouquet Cattleya Hair B Side Ponytail"에서 "Koharu"는 캐릭터 이름으로 해석되며, 나머지 "Bouquet Cattleya Hair B Side Ponytail"은 그녀의 의상을 설명하는 데 사용됩니다.

언어 모델은 잘 알려진 캐릭터의 경우 해당 캐릭터에 대한 지식을 가질 수 있으므로, 때때로 그들이 누구인지와 그들이 어떻게 행동하는지를 인식할 수 있습니다, 특히 OpenAI를 사용할 때 더욱 그렇습니다.

캐릭터 설정에서는 캐릭터에 대한 설명과 성격을 입력할 수 있으며, 이는 캐릭터의 채팅 행동에 큰 영향을 미칩니다. 예를 들어, 자랑스럽고 오만한 캐릭터를 "복종하고 기쁨을 주고 싶어하는"으로 설명하기만 하면 순종적으로 변화시킬 수 있습니다.

"플레이어"는 기술적으로도 캐릭터입니다. 자신의 이름, 설명, 성격을 변경하여 원하는 누구로든 바뀔 수 있습니다.


### 페르소나
캐릭터 설정에는 페르소나 드롭다운이 있습니다. 이는 TavernAI와 같은 AI 롤플레이 프로그램에서 다운로드한 캐릭터를 사용할 수 있도록 해줍니다. 이들은 일반적으로 PNG 포맷으로 제공됩니다. PNG 이미지의 메타데이터에는 캐릭터에 대한 설명이 포함되어 있습니다.

이 온라인 캐릭터 편집기를 사용하여 png 캐릭터를 json 형식으로 변환합니다: [https://zoltanai.github.io/character-editor/](https://zoltanai.github.io/character-editor/)

그런 다음 json 파일을 "chat/personas" 폴더에 넣으면 캐릭터 설정의 페르소나 드롭다운에 나타납니다. 이렇게 하면 페르소나의 설명이 캐릭터 설명을 덮어쓰게 됩니다.


### 채팅 기록
채팅 기록은 새로운 콘텐츠를 생성할 때마다 AI에 전송되어 맥락을 유지하도록 합니다. 다른 시나리오나 주제로 전환하고 싶다면, AI가 이전 채팅 맥락에 영향을 받지 않도록 먼저 기록을 지우십시오. 이렇게 하여 환경을 조작하고 채팅을 이끌어갈 수도 있습니다. 예를 들어 메시지에서 무언가가 발생했다고 설명하면 AI는 그 맥락을 계속 따릅니다.

프롬프트 제한이 도달하면 가장 오래된 메시지는 무시되며 맥락에 포함되지 않습니다. 따라서 AI는 기록에서 너무 멀리 있는 것들을 잊을 수 있습니다.

채팅 인터페이스에서 채팅 메시지 옆의 아이콘을 클릭하여 채팅 기록을 조작할 수 있습니다. 옵션은 다음과 같습니다:

* 재생성: 모든 메시지를 삭제하고 AI가 이 메시지를 재생성하도록 함
* 수정: 메시지를 인수하고 직접 수정함. 이렇게 하면 메시지의 이름과 콜론을 그대로 유지해야 시스템이 이 메시지의 출처를 알 수 있습니다.
* 재생: 이 메시지부터 채팅 기록을 재생함
* 항목 삭제: 이 메시지를 삭제
* 위로 삭제: 이 메시지 위의 모든 메시지를 삭제
* 아래로 삭제: 이 메시지 아래의 모든 메시지를 삭제


### 온도
이 값은 AI 모델이 채팅 메시지를 생성할 때 얼마나 자유롭게 할 수 있는지를 제어합니다. 이미지 생성과 마찬가지로 동일한 입력으로 생성할 때마다 약간씩 다를 수 있으며, 온도는 그 변동성을 조절합니다.


### 존재 패널티 및 빈도 패널티
이 값을 증가시키면 AI가 반복하는 콘텐츠를 생성할 가능성을 줄일 수 있습니다.


### 최대 생성 토큰 및 최대 프롬프트 길이
LLM은 토큰 한도가 있으며, 이 한도를 초과하는 콘텐츠는 올바르게 생성되지 않습니다.


### 자동 생성 및 플레이어를 위한 생성
"자동 생성 다음"을 켜면 타이머가 만료되었을 때 AI가 자동으로 다음 메시지를 생성하도록 할 수 있습니다.

"플레이어를 위한 생성"을 켜면 AI가 플